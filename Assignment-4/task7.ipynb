{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0526bb40",
   "metadata": {},
   "source": [
    "1. What are the assumptions of linear regression?\n",
    "- Linear regression assumes a linear relationship between the independent and dependent variables. It also assumes homoscedasticity (constant variance of errors), independence of observations, no multicollinearity among predictors, and normally distributed residuals.\n",
    "\n",
    "2. When should you use logistic regression instead of linear regression?\n",
    "- Logistic regression is used when the dependent variable is categorical, typically binary (e.g., 0 or 1, yes or no), whereas linear regression is used for predicting continuous outcomes.\n",
    "\n",
    "3. What is the interpretation of coefficients in logistic regression?\n",
    "- In logistic regression, the coefficients represent the change in the log-odds of the outcome for a one-unit increase in the predictor variable, holding other variables constant.\n",
    "\n",
    "4. What is the difference between sigmoid and softmax functions?\n",
    "- The sigmoid function maps a single input to a value between 0 and 1, making it suitable for binary classification. The softmax function, on the other hand, is used in multi-class classification and outputs a probability distribution over multiple classes that sums to 1.\n",
    "\n",
    "5. Why is R-squared not suitable for evaluating logistic regression models?\n",
    "- R-squared measures the proportion of variance explained in linear regression, which assumes continuous outcomes. Logistic regression deals with probabilities and categorical outcomes, so metrics like accuracy, precision, recall, and AUC-ROC are more appropriate."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
